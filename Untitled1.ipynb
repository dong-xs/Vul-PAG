{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5930ee2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['nsubj', 'nsubj', 'prep', 'det', 'compound', 'pobj', 'prep', 'pobj', 'prep', 'compound', 'compound', 'compound', 'compound', 'pobj', 'punct', 'ROOT', 'amod', 'nsubj', 'aux', 'ccomp', 'amod', 'dobj', 'prep', 'det', 'amod', 'pobj', 'punct']\n",
      "[('Buffer', 'NN'), ('overflow', 'NN'), ('in', 'IN'), ('the', 'DT'), ('changevalue', 'NN'), ('function', 'NN'), ('in', 'IN'), ('libcgi.h', 'NN'), ('for', 'IN'), ('Marcos', 'NNP'), ('Luiz', 'NNP'), ('Onisto', 'NNP'), ('Lib', 'NNP'), ('CGI', 'NNP'), ('0.1', 'CD'), ('allows', 'VBZ'), ('remote', 'JJ'), ('attackers', 'NNS'), ('to', 'TO'), ('execute', 'VB'), ('arbitrary', 'JJ'), ('code', 'NN'), ('via', 'IN'), ('a', 'DT'), ('long', 'JJ'), ('argument', 'NN'), ('.', '.')]\n",
      "VBZ\n",
      "1\n",
      "------------------------------------------------------\n",
      "['nsubj', 'ROOT', 'prep', 'det', 'amod', 'compound', 'pobj', 'prep', 'pobj', 'nummod', 'prep', 'compound', 'pobj', 'mark', 'nsubj', 'advcl', 'amod', 'nsubj', 'aux', 'ccomp', 'amod', 'dobj', 'prep', 'pobj', 'prep', 'amod', 'compound', 'pobj', 'punct']\n",
      "[('Buffer', 'NN'), ('overflow', 'NN'), ('in', 'IN'), ('the', 'DT'), ('French', 'JJ'), ('documentation', 'NN'), ('patch', 'NN'), ('for', 'IN'), ('Gnuplot', 'NNP'), ('3.7', 'CD'), ('in', 'IN'), ('SuSE', 'NNP'), ('Linux', 'NNP'), ('before', 'IN'), ('8.0', 'CD'), ('allows', 'VBZ'), ('local', 'JJ'), ('users', 'NNS'), ('to', 'TO'), ('execute', 'VB'), ('arbitrary', 'JJ'), ('code', 'NN'), ('as', 'IN'), ('root', 'NN'), ('via', 'IN'), ('unknown', 'JJ'), ('attack', 'NN'), ('vectors', 'NNS'), ('.', '.')]\n",
      "NN\n",
      "-1\n",
      "------------------------------------------------------\n",
      "['subtok', 'subtok', 'compound', 'compound', 'ROOT', 'punct', 'nmod', 'punct', 'ROOT', 'prep', 'det', 'compound', 'pobj', 'prep', 'compound', 'compound', 'compound', 'pobj', 'nummod', 'prep', 'pobj', 'punct', 'appos', 'punct', 'appos', 'punct', 'npadvmod', 'prep', 'pobj', 'punct', 'appos', 'prep', 'pobj', 'punct', 'cc', 'conj', 'prep', 'pobj', 'punct', 'cc', 'compound', 'conj', 'nsubj', 'appos', 'prep', 'pobj', 'cc', 'conj', 'prep', 'pobj', 'punct', 'ROOT', 'amod', 'nsubj', 'aux', 'ccomp', 'dobj', 'cc', 'conj', 'compound', 'dobj', 'prep', 'amod', 'pobj', 'prep', 'det', 'compound', 'pobj', 'punct']\n",
      "[('Cross-site', 'JJ'), ('request', 'NN'), ('forgery', 'NN'), ('(', '-LRB-'), ('CSRF', 'NN'), (')', '-RRB-'), ('vulnerability', 'NN'), ('in', 'IN'), ('the', 'DT'), ('administration', 'NN'), ('interface', 'NN'), ('in', 'IN'), ('Cisco', 'NNP'), ('IronPort', 'NNP'), ('Encryption', 'NNP'), ('Appliance', 'NNP'), ('6.2.4', 'CD'), ('before', 'IN'), ('6.2.4.1.1', 'CD'), (',', ','), ('6.2.5', 'CD'), (',', ','), ('6.2.6', 'CD'), (',', ','), ('6.2.7', 'CD'), ('before', 'IN'), ('6.2.7.7', 'CD'), (',', ','), ('6.3', 'CD'), ('before', 'IN'), ('6.3.0.4', 'CD'), (',', ','), ('and', 'CC'), ('6.5', 'CD'), ('before', 'IN'), ('6.5.0.2', 'CD'), (';', ':'), ('and', 'CC'), ('Cisco', 'NNP'), ('IronPort', 'NNP'), ('PostX', 'NNP'), ('6.2.1', 'CD'), ('before', 'IN'), ('6.2.1.1', 'CD'), ('and', 'CC'), ('6.2.2', 'CD'), ('before', 'IN'), ('6.2.2.3', 'CD'), (';', ':'), ('allows', 'VBZ'), ('remote', 'JJ'), ('attackers', 'NNS'), ('to', 'TO'), ('execute', 'VB'), ('commands', 'NNS'), ('and', 'CC'), ('modify', 'VB'), ('appliance', 'NN'), ('preferences', 'NNS'), ('as', 'IN'), ('arbitrary', 'JJ'), ('users', 'NNS'), ('via', 'IN'), ('a', 'DT'), ('logout', 'JJ'), ('action', 'NN'), ('.', '.')]\n",
      "NN\n",
      "-1\n",
      "------------------------------------------------------\n",
      "['det', 'ROOT', 'prep', 'det', 'compound', 'compound', 'pobj', 'appos', 'mark', 'advcl', 'prep', 'compound', 'pobj', 'appos', 'cc', 'advmod', 'conj', 'det', 'nsubj', 'aux', 'ccomp', 'compound', 'dobj', 'punct']\n",
      "[('A', 'DT'), ('vulnerability', 'NN'), ('in', 'IN'), ('the', 'DT'), ('Sendmail', 'NNP'), ('configuration', 'NN'), ('file', 'NN'), ('sendmail.cf', 'NN'), ('as', 'IN'), ('installed', 'VBN'), ('in', 'IN'), ('SCO', 'NNP'), ('UnixWare', 'NNP'), ('7.1.0', 'CD'), ('and', 'CC'), ('earlier', 'JJR'), ('allows', 'VBZ'), ('an', 'DT'), ('attacker', 'NN'), ('to', 'TO'), ('gain', 'VB'), ('root', 'NN'), ('privileges', 'NNS'), ('.', '.')]\n",
      "NN\n",
      "-1\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "import pandas as pd\n",
    "import csv\n",
    "from spacy import displacy\n",
    "from stanfordcorenlp import StanfordCoreNLP\n",
    "\n",
    "nlp = spacy.load('en_core_web_md')\n",
    "nlp1 = StanfordCoreNLP('stanford-corenlp-full-2016-10-31', lang='en')\n",
    "\n",
    "pos_tag = ['VB', 'VBP', 'VBZ', 'VBN', 'VBG', 'VBD']  # 表示明确可以作为谓语动词的词性,其中'VB','VBP','VBZ'肯定是可以直接作为谓语动词的\n",
    "\n",
    "\n",
    "def imcomplete_parse_sentence(item):\n",
    "    docs = nlp(item)\n",
    "    deps = [token.dep_ for token in docs]\n",
    "    counts = deps.count('ROOT')\n",
    "    displacy.render(docs,style='dep',jupyter=True,options={'distance':90})\n",
    "    return 1 if counts > 1 else -1   #若返回1，则表示一句话中有多个ROOT，则认为未完全处理，若返回-1，则表示只有一个ROOT，则认为已完全处理\n",
    "\n",
    "def wrong_parse_sentence(item,pos_tags):\n",
    "    docs=nlp(item)\n",
    "    deps=[token.dep_ for token in docs]\n",
    "    print(deps)\n",
    "    #pos=[token.pos_ for token in docs]     #spacy的pos功能中，动词只有VERB一个表示形式，而无法明确表示出其时态及语态，因此考虑使用stanfordcorenl来代替\n",
    "    pos=nlp1.pos_tag(item)\n",
    "    print(pos)\n",
    "    index=deps.index('ROOT')  #先找到第一个ROOT的索引位置，再找这个索引位置上的词性是否在pos_tag中\n",
    "    pos_index=pos[index][-1]\n",
    "    print(pos_index)\n",
    "    return 1 if pos_index in pos_tags else -1    #如果每一个root的词性不在动词标签中，则返回1，表示未正确解析；否则返回-1，表示正确解析了。\n",
    "\n",
    "#受特殊符号影响，而无法完全解析的例子\n",
    "sentence='Signed integer overflow in the bttv_read function in the bttv driver (bttv-driver.c) in Linux kernel before 2.4.20 has unknown impact and attack vectors.'\n",
    "sentence1='Directory traversal vulnerability in (1) Deerfield D2Gfx 1.0.2 or (2) BadBlue Enterprise Edition 1.5.x and BadBlue Personal Edition 1.5.6 allows remote attackers to read arbitrary files via a ../ (dot dot slash) in the script used to read Microsoft Office documents.'\n",
    "sentence2='The wrap CGI program in IRIX allows remote attackers to view arbitrary directory listings via a .. (dot dot) attack.'\n",
    "#print(imcomplete_parse_sentence(sentence2))\n",
    "\n",
    "#未正确解析的例子\n",
    "sentence3='Buffer overflow in the changevalue function in libcgi.h for Marcos Luiz Onisto Lib CGI 0.1 allows remote attackers to execute arbitrary code via a long argument.'\n",
    "sentence4='Buffer overflow in the French documentation patch for Gnuplot 3.7 in SuSE Linux before 8.0 allows local users to execute arbitrary code as root via unknown attack vectors.'\n",
    "sentence5='Cross-site request forgery (CSRF) vulnerability in the administration interface in Cisco IronPort Encryption Appliance 6.2.4 before 6.2.4.1.1, 6.2.5, 6.2.6, 6.2.7 before 6.2.7.7, 6.3 before 6.3.0.4, and 6.5 before 6.5.0.2; and Cisco IronPort PostX 6.2.1 before 6.2.1.1 and 6.2.2 before 6.2.2.3; allows remote attackers to execute commands and modify appliance preferences as arbitrary users via a logout action.'\n",
    "sentence6='A vulnerability in the Sendmail configuration file sendmail.cf as installed in SCO UnixWare 7.1.0 and earlier allows an attacker to gain root privileges.'\n",
    "print(wrong_parse_sentence(sentence3,pos_tag))\n",
    "print('------------------------------------------------------')\n",
    "print(wrong_parse_sentence(sentence4,pos_tag))\n",
    "print('------------------------------------------------------')\n",
    "print(wrong_parse_sentence(sentence5,pos_tag))\n",
    "print('------------------------------------------------------')\n",
    "print(wrong_parse_sentence(sentence6,pos_tag))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "890a503a",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "imcomplete_parse_sentence() missing 2 required positional arguments: 'docs' and 'deps'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_13280/3371113469.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[0mdoc1\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnlp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msentence1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[0mdep1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mtoken\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdep_\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mtoken\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdoc1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 33\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimcomplete_parse_sentence\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msentence2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     34\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[1;31m#未正确解析的例子\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: imcomplete_parse_sentence() missing 2 required positional arguments: 'docs' and 'deps'"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "import pandas as pd\n",
    "import csv\n",
    "from spacy import displacy\n",
    "from stanfordcorenlp import StanfordCoreNLP\n",
    "\n",
    "nlp = spacy.load('en_core_web_lg')\n",
    "nlp1 = StanfordCoreNLP('stanford-corenlp-full-2016-10-31', lang='en')\n",
    "\n",
    "pos_tag = ['VB', 'VBP', 'VBZ', 'VBN', 'VBG', 'VBD']  # 表示明确可以作为谓语动词的词性,其中'VB','VBP','VBZ'肯定是可以直接作为谓语动词的\n",
    "\n",
    "def imcomplete_parse_sentence(item, docs, deps):\n",
    "    counts = deps.count('ROOT')\n",
    "    #displacy.render(docs, style='dep', jupyter=True, options={'distance': 90})\n",
    "    return 1 if counts > 1 else -1  # 若返回1，则表示一句话中有多个ROOT，则认为未完全处理，若返回-1，则表示只有一个ROOT，则认为已完全处理\n",
    "\n",
    "\n",
    "def wrong_parse_sentence(item, pos_tags, docs, deps, pos):\n",
    "    index = deps.index('ROOT')  # 先找到第一个ROOT的索引位置，再找这个索引位置上的词性是否在pos_tag中\n",
    "    pos_index = pos[index][-1]\n",
    "    return 1 if pos_index in pos_tags else -1  # 如果每一个root的词性不在动词标签中，则返回1，表示未正确解析；否则返回-1，表示正确解析了。\n",
    "\n",
    "\n",
    "sentence='Signed integer overflow in the bttv_read function in the bttv driver (bttv-driver.c) in Linux kernel before 2.4.20 has unknown impact and attack vectors.'\n",
    "sentence1='Directory traversal vulnerability in (1) Deerfield D2Gfx 1.0.2 or (2) BadBlue Enterprise Edition 1.5.x and BadBlue Personal Edition 1.5.6 allows remote attackers to read arbitrary files via a ../ (dot dot slash) in the script used to read Microsoft Office documents.'\n",
    "sentence2='The wrap CGI program in IRIX allows remote attackers to view arbitrary directory listings via a .. (dot dot) attack.'\n",
    "doc=nlp(sentence)\n",
    "dep = [token.dep_ for token in doc]\n",
    "doc2=nlp(sentence2)\n",
    "dep2 = [token.dep_ for token in doc2]\n",
    "doc1=nlp(sentence1)\n",
    "dep1 = [token.dep_ for token in doc1]\n",
    "print(imcomplete_parse_sentence(sentence2))\n",
    "\n",
    "#未正确解析的例子\n",
    "sentence3='Buffer overflow in the changevalue function in libcgi.h for Marcos Luiz Onisto Lib CGI 0.1 allows remote attackers to execute arbitrary code via a long argument.'\n",
    "sentence4='Buffer overflow in the French documentation patch for Gnuplot 3.7 in SuSE Linux before 8.0 allows local users to execute arbitrary code as root via unknown attack vectors.'\n",
    "doc3=nlp(sentence3)\n",
    "pos3 = nlp1.pos_tag(sentence3)\n",
    "dep3 = [token.dep_ for token in doc3]\n",
    "doc4=nlp(sentence4)\n",
    "pos4 = nlp1.pos_tag(sentence4)\n",
    "dep4 = [token.dep_ for token in doc4]\n",
    "print(wrong_parse_sentence(sentence3,pos_tag))\n",
    "print('------------------------------------------------------')\n",
    "print(wrong_parse_sentence(sentence4,pos_tag))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0bee69ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "1\n",
      "T\n",
      "h\n",
      "e\n",
      "r\n",
      "e\n",
      " \n",
      "i\n",
      "s\n",
      " \n",
      "a\n",
      " \n",
      "u\n",
      "s\n",
      "e\n",
      "-\n",
      "a\n",
      "f\n",
      "t\n",
      "e\n",
      "r\n",
      "-\n",
      "f\n",
      "r\n",
      "e\n",
      "e\n",
      " \n",
      "v\n",
      "u\n",
      "l\n",
      "n\n",
      "e\n",
      "r\n",
      "a\n",
      "b\n",
      "i\n",
      "l\n",
      "i\n",
      "t\n",
      "y\n",
      " \n",
      "i\n",
      "n\n",
      " \n",
      "t\n",
      "h\n",
      "e\n",
      " \n",
      "L\n",
      "i\n",
      "n\n",
      "u\n",
      "x\n",
      " \n",
      "k\n",
      "e\n",
      "r\n",
      "n\n",
      "e\n",
      "l\n",
      " \n",
      "t\n",
      "h\n",
      "r\n",
      "o\n",
      "u\n",
      "g\n",
      "h\n",
      " \n",
      "5\n",
      ".\n",
      "5\n",
      ".\n",
      "2\n",
      " \n",
      "i\n",
      "n\n",
      " \n",
      "t\n",
      "h\n",
      "e\n",
      " \n",
      "v\n",
      "g\n",
      "a\n",
      "c\n",
      "o\n",
      "n\n",
      "_\n",
      "i\n",
      "n\n",
      "v\n",
      "e\n",
      "r\n",
      "t\n",
      "_\n",
      "r\n",
      "e\n",
      "g\n",
      "i\n",
      "o\n",
      "n\n",
      " \n",
      "f\n",
      "u\n",
      "n\n",
      "c\n",
      "t\n",
      "i\n",
      "o\n",
      "n\n",
      " \n",
      "i\n",
      "n\n",
      " \n",
      "d\n",
      "r\n",
      "i\n",
      "v\n",
      "e\n",
      "r\n",
      "s\n",
      "/\n",
      "v\n",
      "i\n",
      "d\n",
      "e\n",
      "o\n",
      "/\n",
      "c\n",
      "o\n",
      "n\n",
      "s\n",
      "o\n",
      "l\n",
      "e\n",
      "/\n",
      "v\n",
      "g\n",
      "a\n",
      "c\n",
      "o\n",
      "n\n",
      ".\n",
      "c\n",
      ".\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "from stanfordcorenlp import StanfordCoreNLP\n",
    "import nltk\n",
    "\n",
    "stanfor_nlp=StanfordCoreNLP(r'stanford-corenlp-full-2016-10-31', lang='en')\n",
    "spacy_nlp=spacy.load('en_core_web_md')\n",
    "sent1='Signed integer overflow in the bttv_read function in the bttv driver (bttv-driver.c) in Linux kernel before 2.4.20 has unknown impact and attack vectors.'\n",
    "sent2='eG Manager 7.1.2 allows authentication bypass via a com.egurkha.EgLoginServlet?uname=admin&upass=&accessKey=eGm0n1t0r request.'\n",
    "sent3='Trend Micro Apex One (2019), OfficeScan XG and Worry-Free Business Security (9.0, 9.5, 10.0) server contains a vulnerable service DLL file that could allow a remote attacker to execute arbitrary code on affected installations with SYSTEM level privileges. '\n",
    "sent4='There is a use-after-free vulnerability in the Linux kernel through 5.5.2 in the vgacon_invert_region function in drivers/video/console/vgacon.c.'\n",
    "# pos_list=stanfor_nlp.pos_tag(sent)\n",
    "# print(pos_list)\n",
    "# tags=[tag[1] for tag in pos_list]\n",
    "# print(tags)\n",
    "\n",
    "# doc1=spacy_nlp(sent2)\n",
    "# tokens=[token for token in doc1]\n",
    "# word1=[token.dep_ for token in doc1]\n",
    "# print(tokens)    #能对比出来，spacy处理句子效果更好，仅针对sent2；但针对sent3及sent4，stanford的处理效果更好。归根结底，还需要对其分词前设定规则\n",
    "# print(word1)\n",
    "# print('=======================================================')\n",
    "# stan_result=stanfor_nlp.dependency_parse(sent2)\n",
    "# tokens_stan=stanfor_nlp.word_tokenize(sent2)\n",
    "# print(tokens_stan)\n",
    "# print(stan_result)\n",
    "\n",
    "# sent_text1=nltk.sent_tokenize(sent1)\n",
    "# print(sent_text1)\n",
    "# print('=======================================================')\n",
    "# sent_text2=nltk.sent_tokenize(sent2)\n",
    "# print(sent_text2)\n",
    "# print('=======================================================')\n",
    "# sent_text3=nltk.sent_tokenize(sent3)\n",
    "# print(sent_text3)\n",
    "# print('=======================================================')\n",
    "sent_text4=nltk.sent_tokenize(sent4)\n",
    "print(type(sent_text4))\n",
    "print(len(sent_text4))\n",
    "for item in sent_text4[0]:\n",
    "    print(item)\n",
    "\n",
    "# doc2=spacy_nlp(sent2)\n",
    "# word2=[token.dep_ for token in doc2]\n",
    "# print(word2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0a2ad723",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('abc', 3)\n"
     ]
    }
   ],
   "source": [
    "def getmaxstr(str1,str2):\n",
    "    lstr1=len(str1)\n",
    "    lstr2=len(str2)\n",
    "    record=[[0 for i in range(lstr2+1)] for j in range(lstr1+1)]\n",
    "    maxNum=0\n",
    "    p=0\n",
    "    for i in range(lstr1):\n",
    "        for j in range(lstr2):\n",
    "            if str1[i]==str2[j]:\n",
    "                record[i+1][j+1]=record[i][j]+1\n",
    "                if record[i+1][j+1]>maxNum:\n",
    "                    maxNum=record[i+1][j+1]\n",
    "                    p=i+1\n",
    "    return str1[p-maxNum:p],maxNum\n",
    "\n",
    "x='abcdefg'\n",
    "y='abcefgh'\n",
    "\n",
    "print(getmaxstr(x,y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8a39d0ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 'abc')\n"
     ]
    }
   ],
   "source": [
    "def getMaxCommonSubstr(s1, s2):\n",
    "# 求两个字符串的最长公共子串\n",
    "# 思想：建立一个二维数组，保存连续位相同与否的状态\n",
    "\n",
    "    len_s1 = len(s1)\n",
    "    len_s2 = len(s2)\n",
    "\n",
    "    # 生成0矩阵，为方便后续计算，多加了1行1列\n",
    "    # 行: (len_s1+1)\n",
    "    # 列: (len_s2+1)\n",
    "    record = [[0 for i in range(len_s2+1)] for j in range(len_s1+1)]    \n",
    "    \n",
    "    maxNum = 0          # 最长匹配长度\n",
    "    p = 0               # 字符串匹配的终止下标 \n",
    "\n",
    "    for i in range(len_s1):\n",
    "        for j in range(len_s2):\n",
    "            if s1[i] == s2[j]:\n",
    "                # 相同则累加\n",
    "                record[i+1][j+1] = record[i][j] + 1\n",
    "                \n",
    "                if record[i+1][j+1] > maxNum:\n",
    "                    maxNum = record[i+1][j+1]\n",
    "                    p = i # 匹配到下标i\n",
    "\n",
    "    # 返回 子串长度，子串\n",
    "    return maxNum, s1[p+1-maxNum : p+1]\n",
    "\n",
    "x='abcdefg'\n",
    "y='abcefgh'\n",
    "\n",
    "print(getMaxCommonSubstr(x,y))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cc02356",
   "metadata": {},
   "source": [
    "print(1/2.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6eceb802",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Improper, Input, Validation, in, Teltonika, firmware, TRB2_R_00.02.04.01, allows, a, remote, ,, authenticated, attacker, to, gain, root, privileges, by, uploading, a, malicious, package, file, .]\n",
      "['compound', 'compound', 'nsubj', 'prep', 'compound', 'pobj', 'punct', 'ROOT', 'det', 'amod', 'punct', 'amod', 'nsubj', 'aux', 'ccomp', 'compound', 'dobj', 'prep', 'pcomp', 'det', 'amod', 'compound', 'dobj', 'punct']\n",
      "['ADJ', 'PROPN', 'PROPN', 'ADP', 'PROPN', 'NOUN', 'PROPN', 'VERB', 'DET', 'ADJ', 'PUNCT', 'VERB', 'NOUN', 'PART', 'VERB', 'NOUN', 'NOUN', 'ADP', 'VERB', 'DET', 'ADJ', 'NOUN', 'NOUN', 'PUNCT']\n"
     ]
    }
   ],
   "source": [
    "sent='NVIDIA Linux GPU Display Driver, all versions, contains a vulnerability in the UVM driver, in which a race condition may lead to a denial of service.'\n",
    "sent1='Improper Input Validation in Teltonika firmware TRB2_R_00.02.04.01 allows a remote, authenticated attacker to gain root privileges by uploading a malicious package file.'\n",
    "\n",
    "import spacy\n",
    "spacy_nlp=spacy.load('en_core_web_md')\n",
    "\n",
    "doc=spacy_nlp(sent1)\n",
    "\n",
    "print([token for token in doc])\n",
    "print([token.dep_ for token in doc])\n",
    "print([token.pos_ for token in doc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "775def7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(By, 'prep', allows), (leveraging, 'pcomp', By), (an, 'det', connection), (NFC, 'compound', connection), (connection, 'dobj', leveraging), (to, 'aux', access), (access, 'acl', connection), (the, 'det', server), (HTTP, 'compound', server), (server, 'dobj', access), (on, 'prep', server), (port, 'pobj', on), (15000，Samsung, 'compound', SBeam), (SBeam, 'pobj', on), (allows, 'ROOT', allows), (remote, 'amod', attackers), (attackers, 'nsubj', read), (to, 'aux', read), (read, 'ccomp', allows), (arbitrary, 'amod', images), (images, 'dobj', read), (., 'punct', allows)]\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "sent='SQL injection vulnerability in Pragyan CMS 3.0.'\n",
    "sent1='dayrui FineCms 5.2.0 before 2017.11.16 has Cross Site Scripting (XSS) in core/M_Controller.php via the DR_URI field.'\n",
    "sent2=\"XML external entity (XXE) vulnerability in bkr/server/jobs.py in Beaker before 20.1 allows remote authenticated users to obtain sensitive information via submitting job XML to the server containing entity references which reference files from the Beaker server's file system.\"\n",
    "sent3='daemon/abrt-handle-upload.in in Automatic Bug Reporting Tool (ABRT), when moving problem reports from /var/spool/abrt-upload, allows local users to write to arbitrary files or possibly have other unspecified impact via a symlink attack on (1) /var/spool/abrt or (2) /var/tmp/abrt'\n",
    "sent4='PolicyKit (aka polkit) before 0.113 allows local users to cause a denial of service (memory corruption and polkitd daemon crash) and possibly gain privileges via unspecified vectors, related to \"\"javascript rule evaluation.\"\"'\n",
    "sent5='The HTTP/2 experimental feature in Apache Traffic Server 5.3.x before 5.3.1 allows remote attackers to cause a denial of service (out-of-bounds access and daemon crash) or possibly execute arbitrary code via vectors related to the (1) frame_handlers array or (2) set_dynamic_table_size function.'\n",
    "sent6='Cross-site scripting (XSS) vulnerability in the Orchestration/Stack section in OpenStack Dashboard (Horizon) 2014.2 before 2014.2.4 and 2015.1.x before 2015.1.1 allows remote attackers to inject arbitrary web script or HTML via the description parameter in a heat template, which is not properly handled in the help_text attribute in the Field class.'\n",
    "sent7=\"The OpenID module in Drupal 6.x before 6.36 and 7.x before 7.38 allows remote attackers to log into other users' accounts by leveraging an OpenID identity from certain providers, as demonstrated by the Verisign, LiveJournal, and StackExchange providers.\"\n",
    "sent8='Pydio (formerly AjaXplorer) before 6.0.7 allows remote attackers to execute arbitrary commands via unspecified vectors, aka \"\"Pydio OS Command Injection Vulnerabilities.\"\"'\n",
    "#sent9='Samsung SBeam allows remote attackers to read arbitrary images by leveraging an NFC connection to access the HTTP server on port 15000.'\n",
    "sent9='By leveraging an NFC connection to access the HTTP server on port 15000，Samsung SBeam allows remote attackers to read arbitrary images.'\n",
    "sent10='Cisco IOS XR 5.2.1 allows remote attackers to cause a denial of service (ipv6_io service reload) via a malformed IPv6 packet, aka Bug ID CSCuq95565.'\n",
    "spa_nlp=spacy.load('en_core_web_md')\n",
    "\n",
    "doc=spa_nlp(sent9)\n",
    "\n",
    "print([(token,token.dep_,token.head) for token in doc])\n",
    "# print([token.dep_ for token in doc])\n",
    "#print([token.pos_ for token in doc])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1f10cbf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['nsubj', 'ROOT', 'prep', 'det', 'amod', 'compound', 'pobj', 'prep', 'pobj', 'nummod', 'prep', 'compound', 'pobj', 'mark', 'nsubj', 'advcl', 'amod', 'nsubj', 'aux', 'ccomp', 'amod', 'dobj', 'prep', 'pobj', 'prep', 'amod', 'compound', 'pobj', 'punct']\n",
      "Buffer\n",
      "++++++++++++++++++++++++++++++++\n",
      "Buffer\n",
      "overflow\n",
      "in\n",
      "the\n",
      "French\n",
      "documentation\n",
      "patch\n",
      "for\n",
      "Gnuplot\n",
      "3.7\n",
      "in\n",
      "SuSE\n",
      "Linux\n",
      "before\n",
      "8.0\n",
      "allows\n",
      "local\n",
      "users\n",
      "to\n",
      "execute\n",
      "arbitrary\n",
      "code\n",
      "as\n",
      "root\n",
      "via\n",
      "unknown\n",
      "attack\n",
      "vectors\n",
      ".\n",
      "++++++++++++++++++++++++++++++++\n",
      "in\n",
      "the\n",
      "French\n",
      "documentation\n",
      "patch\n",
      "for\n",
      "Gnuplot\n",
      "3.7\n",
      "in\n",
      "SuSE\n",
      "Linux\n",
      "++++++++++++++++++++++++++++++++\n",
      "the\n",
      "++++++++++++++++++++++++++++++++\n",
      "French\n",
      "++++++++++++++++++++++++++++++++\n",
      "documentation\n",
      "++++++++++++++++++++++++++++++++\n",
      "the\n",
      "French\n",
      "documentation\n",
      "patch\n",
      "for\n",
      "Gnuplot\n",
      "3.7\n",
      "in\n",
      "SuSE\n",
      "Linux\n",
      "++++++++++++++++++++++++++++++++\n",
      "for\n",
      "Gnuplot\n",
      "3.7\n",
      "in\n",
      "SuSE\n",
      "Linux\n",
      "++++++++++++++++++++++++++++++++\n",
      "Gnuplot\n",
      "3.7\n",
      "in\n",
      "SuSE\n",
      "Linux\n",
      "++++++++++++++++++++++++++++++++\n",
      "3.7\n",
      "++++++++++++++++++++++++++++++++\n",
      "in\n",
      "SuSE\n",
      "Linux\n",
      "++++++++++++++++++++++++++++++++\n",
      "SuSE\n",
      "++++++++++++++++++++++++++++++++\n",
      "SuSE\n",
      "Linux\n",
      "++++++++++++++++++++++++++++++++\n",
      "before\n",
      "++++++++++++++++++++++++++++++++\n",
      "8.0\n",
      "++++++++++++++++++++++++++++++++\n",
      "before\n",
      "8.0\n",
      "allows\n",
      "local\n",
      "users\n",
      "to\n",
      "execute\n",
      "arbitrary\n",
      "code\n",
      "as\n",
      "root\n",
      "via\n",
      "unknown\n",
      "attack\n",
      "vectors\n",
      "++++++++++++++++++++++++++++++++\n",
      "local\n",
      "++++++++++++++++++++++++++++++++\n",
      "local\n",
      "users\n",
      "++++++++++++++++++++++++++++++++\n",
      "to\n",
      "++++++++++++++++++++++++++++++++\n",
      "local\n",
      "users\n",
      "to\n",
      "execute\n",
      "arbitrary\n",
      "code\n",
      "as\n",
      "root\n",
      "via\n",
      "unknown\n",
      "attack\n",
      "vectors\n",
      "++++++++++++++++++++++++++++++++\n",
      "arbitrary\n",
      "++++++++++++++++++++++++++++++++\n",
      "arbitrary\n",
      "code\n",
      "++++++++++++++++++++++++++++++++\n",
      "as\n",
      "root\n",
      "++++++++++++++++++++++++++++++++\n",
      "root\n",
      "++++++++++++++++++++++++++++++++\n",
      "via\n",
      "unknown\n",
      "attack\n",
      "vectors\n",
      "++++++++++++++++++++++++++++++++\n",
      "unknown\n",
      "++++++++++++++++++++++++++++++++\n",
      "attack\n",
      "++++++++++++++++++++++++++++++++\n",
      "unknown\n",
      "attack\n",
      "vectors\n",
      "++++++++++++++++++++++++++++++++\n",
      ".\n",
      "++++++++++++++++++++++++++++++++\n",
      "================================\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "spacy_nlp=spacy.load('en_core_web_md')\n",
    "# import neuralcoref\n",
    "# coref=neuralcoref.NeuralCoref(spacy_nlp.vocab)\n",
    "# spacy_nlp.add_pipe(coref,name='neuralcoref')\n",
    "sent='My sister has a dog. She loves him.The fixed version is 12.343'\n",
    "\n",
    "sent1='This vulnerability allows remote attackers to execute arbitrary code on vulnerable installations of Foxit Reader 8.3.1.21155. User interaction is required to exploit this vulnerability in that the target must visit a malicious page or open a malicious file. The specific flaw exists within the handling of references to the app object from FormCalc. The issue results from the lack of proper validation of user-supplied data, which can result in a type confusion condition. An attacker can leverage this to execute code in the context of the current process. Was ZDI-CAN-5072.'\n",
    "\n",
    "sent2='Buffer overflow in the French documentation patch for Gnuplot 3.7 in SuSE Linux before 8.0 allows local users to execute arbitrary code as root via unknown attack vectors.'\n",
    "\n",
    "sent3='Denial of service in Qmail through long SMTP commands.'\n",
    "sent4='A Memory Leak issue was discovered in K7Computing K7AntiVirus Premium 15.01.00.53.'\n",
    "\n",
    "from stanfordcorenlp import StanfordCoreNLP\n",
    "# stanford_nlp = StanfordCoreNLP(r'H:\\pycharm_project\\Vul-PAG\\stanford-corenlp-full-2016-10-31', lang='en')\n",
    "\n",
    "# print(stanford_nlp.dependency_parse(sent3))\n",
    "\n",
    "# def get_imcomplete_sentence(sent,pos_tag):\n",
    "#     tags=stanford_nlp.pos_tag(sent)    #获取句子的所有词性标注结果\n",
    "#     print(tags)\n",
    "#     #tags=[token.pos_ for token in doc]\n",
    "#     ret=[i for i in pos_tag if i not in tags]    #求两个列表的交集，\n",
    "#     return 1 if len(ret)==0 else 0   \n",
    "\n",
    "# verb_tags = ['VB', 'VBZ', 'VBP']\n",
    "\n",
    "# print(get_imcomplete_sentence(sent3,verb_tags))\n",
    "# print(get_imcomplete_sentence(sent4,verb_tags))\n",
    "\n",
    "\n",
    "# from nltk import sent_tokenize\n",
    "\n",
    "# def all_sentences(string):   #这一段就是判断整句话的函数\n",
    "#     nltk_sentences = sent_tokenize(string)     #这个函数直接对句子进行了分句\n",
    "#     print(nltk_sentences)\n",
    "#     all_sentences_list = []\n",
    "#     for i in nltk_sentences:\n",
    "#         print(i)\n",
    "#         i.rstrip()\n",
    "#         if i.endswith(\".\") and \"\\n\" not in i:   #如果一句话是以.结束，且\\n不\n",
    "#             all_sentences_list.append(i)\n",
    "#         elif \"\\n\" in i:\n",
    "#             i.split(\"\\n\")\n",
    "#             for j in i.split(\"\\n\"):\n",
    "#                 all_sentences_list.append(j)\n",
    "#     return all_sentences_list\n",
    "\n",
    "# print(all_sentences(sent2))\n",
    "\n",
    "# print(doc._.has_coref)\n",
    "# print(doc._.coref_clusters)\n",
    "\n",
    "# print([token for token in doc])\n",
    "# values=[(token,token.dep_,token.head) for token in doc]\n",
    "# for item in values:\n",
    "\n",
    "\n",
    "#     print(item)\n",
    "\n",
    "doc=spacy_nlp(sent2)\n",
    "print([token.dep_ for token in doc])\n",
    "\n",
    "for item in doc.sents:\n",
    "    for word in item:\n",
    "        temp_tree=word.subtree\n",
    "        for x in temp_tree:\n",
    "            print(x)\n",
    "        print('++++++++++++++++++++++++++++++++')\n",
    "    print('================================')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cfb74f43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Midnight Commander (mc) before 4.5.11 stores usernames and passwords for visited sites in plaintext in the world-readable history file, which allows other local users to gain privileges.\n",
      "Midnight(NNP) <-- compound -- Commander(NNP)\n",
      "Commander(NNP) <-- ROOT -- Commander(NNP)\n",
      "((-LRB-) <-- punct -- mc(NNP)\n",
      "mc(NNP) <-- appos -- Commander(NNP)\n",
      ")(-RRB-) <-- punct -- Commander(NNP)\n",
      "before(IN) <-- prep -- Commander(NNP)\n",
      "4.5.11(CD) <-- nummod -- stores(NNS)\n",
      "stores(NNS) <-- compound -- usernames(NNS)\n",
      "usernames(NNS) <-- pobj -- before(IN)\n",
      "and(CC) <-- cc -- usernames(NNS)\n",
      "passwords(NNS) <-- conj -- usernames(NNS)\n",
      "for(IN) <-- prep -- usernames(NNS)\n",
      "visited(VBN) <-- amod -- sites(NNS)\n",
      "sites(NNS) <-- pobj -- for(IN)\n",
      "in(IN) <-- prep -- sites(NNS)\n",
      "plaintext(NN) <-- pobj -- in(IN)\n",
      "in(IN) <-- prep -- plaintext(NN)\n",
      "the(DT) <-- det -- file(NN)\n",
      "world(NN) <-- npadvmod -- readable(JJ)\n",
      "-(HYPH) <-- punct -- readable(JJ)\n",
      "readable(JJ) <-- amod -- file(NN)\n",
      "history(NN) <-- compound -- file(NN)\n",
      "file(NN) <-- pobj -- in(IN)\n",
      ",(,) <-- punct -- file(NN)\n",
      "which(WDT) <-- nsubj -- allows(VBZ)\n",
      "allows(VBZ) <-- relcl -- file(NN)\n",
      "other(JJ) <-- amod -- users(NNS)\n",
      "local(JJ) <-- amod -- users(NNS)\n",
      "users(NNS) <-- nsubj -- gain(VB)\n",
      "to(TO) <-- aux -- gain(VB)\n",
      "gain(VB) <-- ccomp -- allows(VBZ)\n",
      "privileges(NNS) <-- dobj -- gain(VB)\n",
      ".(.) <-- punct -- Commander(NNP)\n",
      "None\n",
      "=======================================\n"
     ]
    }
   ],
   "source": [
    "#encoding:utf-8\n",
    "'''\n",
    "    该代码的作用是找出每个多句情况下的主语、谓语、宾语。\n",
    "'''\n",
    "\n",
    "import spacy\n",
    "spacy_nlp=spacy.load('en_core_web_md')\n",
    "from nltk import sent_tokenize\n",
    "\n",
    "sent='This vulnerability allows remote attackers to execute arbitrary code on vulnerable installations of Foxit Reader 8.3.1.21155. User interaction is required to exploit this vulnerability in that the target must visit a malicious page or open a malicious file. The specific flaw exists within the handling of references to the app object from FormCalc. The issue results from the lack of proper validation of user-supplied data, which can result in a type confusion condition. An attacker can leverage this to execute code in the context of the current process. Was ZDI-CAN-5072.'\n",
    "sent1='Dell OpenManage Enterprise versions prior to 3.6.1 contain an improper authentication vulnerability. A remote unauthenticated attacker may potentially exploit this vulnerability to hijack an elevated session or perform unauthorized actions by sending malformed data.'\n",
    "sent2='The specific flaw exists within the handling of references to the app object from FormCalc. The issue results from the lack of proper validation of user-supplied data, which can result in a type confusion condition.'\n",
    "sent3='This issue was addressed by encrypting communications over the network to devices running iOS 14, iPadOS 14, tvOS 14, and watchOS 7. This issue is fixed in iOS 14.0 and iPadOS 14.0, Xcode 12.0. An attacker in a privileged network position may be able to execute arbitrary code on a paired device during a debug session over the network.'\n",
    "sent4='An input validation issue was addressed with improved input validation. This issue is fixed in iOS 14.0 and iPadOS 14.0, tvOS 14.0, watchOS 7.0, Safari 14.0, iCloud for Windows 11.4, iCloud for Windows 7.21. Processing maliciously crafted web content may lead to a cross site scripting attack.'\n",
    "sent5='Processing maliciously crafted web content may lead to arbitrary code execution.'\n",
    "sent6='An attacker can leverage this vulnerability to execute code in the context of the admin user. Was ZDI-CAN-8457.'\n",
    "sent7='Midnight Commander (mc) before 4.5.11 stores usernames and passwords for visited sites in plaintext in the world-readable history file, which allows other local users to gain privileges.'\n",
    "lists=sent_tokenize(sent7)\n",
    "\n",
    "def prints(strs):\n",
    "    for item in strs:\n",
    "        print(item)\n",
    "\n",
    "def get_deps_show(sents):\n",
    "    docs=spacy_nlp(sents)\n",
    "    for token in docs:\n",
    "        print('{0}({1}) <-- {2} -- {3}({4})'.format(token.text, token.tag_, token.dep_, token.head.text, token.head.tag_))\n",
    "\n",
    "subj_list=['nsubj','nsubjpass','csubj','csubjpass','agent','expl']  #用于表示主语的标记形式\n",
    "obj_list=['dobj','dative','attr','oprd']    #用于表示宾语的标记形式\n",
    "        \n",
    "# def get_ROOT_subj_obj(docs):\n",
    "#     pos\n",
    "        \n",
    "for items in lists:\n",
    "    print(items)\n",
    "    print(get_deps_show(items))\n",
    "    print('=======================================')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bbc0b28e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "[ES: [ES, ES], The ES File Explorer File Manager application through 4.1.9.7.4 for Android: [The ES File Explorer File Manager application through 4.1.9.7.4 for Android, the ES application], TCP port: [TCP port, This TCP port]]\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "spacy_nlp=spacy.load('en_core_web_md')\n",
    "import neuralcoref\n",
    "coref=neuralcoref.NeuralCoref(spacy_nlp.vocab)\n",
    "spacy_nlp.add_pipe(coref,name='neuralcoref')\n",
    "sent='A validation issue was addressed with improved input sanitization. This issue is fixed in iOS 13.5 and iPadOS 13.5, macOS Catalina 10.15.5. A USB device may be able to cause a denial of service.'\n",
    "sent1='A memory corruption issue was addressed with improved state management. This issue is fixed in iOS 13.5 and iPadOS 13.5, tvOS 13.4.5, watchOS 6.2.5, Safari 13.1.1, iTunes 12.10.7 for Windows, iCloud for Windows 11.2, iCloud for Windows 7.19. Processing maliciously crafted web content may lead to arbitrary code execution.'\n",
    "sent2='A vulnerability in the CLI of Cisco UCS Central Software could allow an authenticated, local attacker to gain shell access. The vulnerability is due to insufficient input validation of commands entered in the CLI, aka a Restricted Shell Break Vulnerability. An attacker could exploit this vulnerability by entering a specific command with crafted arguments. An exploit could allow the attacker to gain shell access to the underlying system. Cisco Bug IDs: CSCve70762.'\n",
    "sent3='A \"Cisco WebEx Network Recording Player Denial of Service Vulnerability\" exists in Cisco WebEx Network Recording Player for Advanced Recording Format (ARF) and WebEx Recording Format (WRF) files. A remote attacker could exploit this by providing a user with a malicious ARF or WRF file via email or URL and convincing the user to launch the file. Exploitation of this could cause an affected player to crash and, in some cases, could allow arbitrary code execution on the system of a targeted user. Cisco Bug IDs: CSCve11545, CSCve02843, CSCve11548.'\n",
    "sent4='This vulnerability allows remote attackers to execute arbitrary code on affected installations of TP-LINK TL-WR841N routers. Authentication is not required to exploit this vulnerability. The specific flaw exists within the web service, which listens on TCP port 80 by default. When parsing the Host request header, the process does not properly validate the length of user-supplied data prior to copying it to a fixed-length static buffer. An attacker can leverage this vulnerability to execute code in the context of the admin user. Was ZDI-CAN-8457.'\n",
    "sent5='The ES File Explorer File Manager application through 4.1.9.7.4 for Android allows remote attackers to read arbitrary files or execute applications via TCP port 59777 requests on the local Wi-Fi network. This TCP port remains open after the ES application has been launched once, and responds to unauthenticated application/json data over HTTP.'\n",
    "doc=spacy_nlp(sent5)\n",
    "print(doc._.has_coref)\n",
    "print(doc._.coref_clusters)\n",
    "\n",
    "# doc1=spacy_nlp(sent3)\n",
    "# print(doc1._.has_coref)\n",
    "# sent1 = 'The GREE application before 1.4.0, GREE Tanken Dorirando application before 1.0.7, GREE Tsurisuta application before 1.5.0, GREE Monpura application before 1.1.1, GREE Kaizokuoukoku Columbus application before 1.3.5, GREE haconiwa application before 1.1.0, GREE Seisen Cerberus application before 1.1.0, and KDDI&GREE GREE Market application before 2.1.2 for Android do not properly implement the WebView class, which allows remote attackers to obtain sensitive information via a crafted application.'\n",
    "# sent2 = 'Unspecified vulnerability in Oracle Java SE 7 Update 11 (JRE 1.7.0_11-b21) allows user-assisted remote attackers to bypass the Java security sandbox via unspecified vectors, aka \"Issue 51,\" a different vulnerability than CVE-2013-0431.  NOTE: as of 20130130, this vulnerability does not contain any independently-verifiable details, and there is no vendor acknowledgement. A CVE identifier is being assigned because this vulnerability has received significant public attention, and the original researcher has an established history of releasing vulnerability reports that have been fixed by vendors.  NOTE: this issue also exists in SE 6, but it cannot be exploited without a separate vulnerability.'\n",
    "# sent3 = 'Unspecified vulnerability in Haakon Nilsen simple, integrated publishing system (SIPS) before 0.2.4 has an unknown impact and attack vectors, related to a \"grave security fault.\" This will cause XSS.'\n",
    "# sent4 = 'Denial of service in Qmail through long SMTP commands.'    #该句子没有动词\n",
    "# sent5 = 'File creation and deletion, and remote execution, in the BSD line printer daemon (lpd).'    print(doc1._.coref_clusters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b4e2312d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VERB\n",
      "15\n",
      "15\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "spacy_nlp=spacy.load('en_core_web_md')\n",
    "subj_tags = ['nsubj', 'nsubjpass', 'csubj', 'csubjpass', 'agent', 'expl']   #其实英文句子必须包含的成分是主语和谓语\n",
    "\n",
    "sent1 = 'The GREE application before 1.4.0, GREE Tanken Dorirando application before 1.0.7, GREE Tsurisuta application before 1.5.0, GREE Monpura application before 1.1.1, GREE Kaizokuoukoku Columbus application before 1.3.5, GREE haconiwa application before 1.1.0, GREE Seisen Cerberus application before 1.1.0, and KDDI&GREE GREE Market application before 2.1.2 for Android do not properly implement the WebView class, which allows remote attackers to obtain sensitive information via a crafted application.'\n",
    "sent2 = 'Unspecified vulnerability in Oracle Java SE 7 Update 11 (JRE 1.7.0_11-b21) allows user-assisted remote attackers to bypass the Java security sandbox via unspecified vectors, aka \"Issue 51,\" a different vulnerability than CVE-2013-0431.  NOTE: as of 20130130, this vulnerability does not contain any independently-verifiable details, and there is no vendor acknowledgement. A CVE identifier is being assigned because this vulnerability has received significant public attention, and the original researcher has an established history of releasing vulnerability reports that have been fixed by vendors.  NOTE: this issue also exists in SE 6, but it cannot be exploited without a separate vulnerability.'\n",
    "sent3 = 'Unspecified vulnerability in Haakon Nilsen simple, integrated publishing system (SIPS) before 0.2.4 has an unknown impact and attack vectors, related to a \"grave security fault.\" This will cause XSS.'\n",
    "sent4 = 'Denial of service in Qmail through long SMTP commands.'    #该句子没有动词\n",
    "sent5 = 'File creation and deletion, and remote execution, in the BSD line printer daemon (lpd).'   \n",
    "\n",
    "def judge_complete_simple_sentence(sent):\n",
    "    docs = spacy_nlp(sent)   #构建doc对象\n",
    "    deps = [item.dep_ for item in docs]   #存放每个词的依赖关系标签\n",
    "    pos = [item.pos_ for item in docs]    #存放每个词的词性标签\n",
    "    heads = [item.head.dep_ for item in docs]  # 存放每个词的前一个词的依赖情况\n",
    "    print(pos[deps.index('ROOT')])\n",
    "    print(deps.index('ROOT'))\n",
    "    verb_index = deps.index('ROOT') if pos[deps.index('ROOT')] == 'VERB' else -1    #若某个词的依赖关系为'ROOT'\n",
    "    print(verb_index)\n",
    "    # 已定位到动词的索引位置，需要找到所有与该ROOT直接关联的词项\n",
    "    if verb_index != -1:    #若存在动词\n",
    "        temp_sub_idx=[]    #存放主语相关的索引位置\n",
    "        # temp_obj_idx = []  #存放宾语相关的索引位置\n",
    "        for value in range(len(heads)):\n",
    "            if heads[value]=='ROOT':\n",
    "                if deps[value] in subj_tags and value<verb_index:    #若该位置上的词在主语标签内且索引值小于动词的位置\n",
    "                    temp_sub_idx.append(value)          #存放与ROOT相关主语依赖关系的索引位置\n",
    "                # elif heads[value] in obj_tags and value>verb_index:  #若该位置上的词在主语标签内且索引值大于动词的位置\n",
    "                #     temp_obj_idx.append(value)          #存放与ROOT相关宾语依赖关系的索引位置\n",
    "        if len(temp_sub_idx)!=0:    #主语标签必定不为0，则认为该句子是完整的\n",
    "            return 1\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "print(judge_complete_simple_sentence(sent3))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "315b0313",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (Temp/ipykernel_15312/1616189772.py, line 10)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"C:\\Users\\dongxs\\AppData\\Local\\Temp/ipykernel_15312/1616189772.py\"\u001b[1;36m, line \u001b[1;32m10\u001b[0m\n\u001b[1;33m    raise ValueError(self.method,\"is not an approriate attention method\".)\u001b[0m\n\u001b[1;37m                                                                         ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class attn(torch.nn.Module):\n",
    "    def __init__(self,method,hidden_size):\n",
    "        super(attn,self).__init__()\n",
    "        self.method=method\n",
    "        if self.method not in ['dot','general','contact']:\n",
    "            raise ValueError(self.method,\"is not an approriate attention method\".)\n",
    "        self.hidden_size=hidden_size\n",
    "        if self.method=='general':\n",
    "            self.attn=torch.nn.Linear(self.hidden_size,hidden_size)\n",
    "        elif self.method=='contact':\n",
    "            self.attn=torch.nn.Linear(self.hidden_size*2,hidden_size)\n",
    "            self.v=torhc.nn.Parameter(torch.FloatTensor(hidden_size))\n",
    "            \n",
    "    def dot_score(self,hidden,encoder_output):\n",
    "        return torch.sum(hidden*encoder_output,dim=2)\n",
    "    \n",
    "    def general_score(self,hidden,encoder_output):\n",
    "        energy=self.attn(encoder_output)\n",
    "        return torch.sum(hidden*energy,dim=2)\n",
    "    \n",
    "    def concat_score(self,hidden,encoder_output):\n",
    "        energy=self.attn(torch.cat((hidden.expand(encoder_output.size(0),-1,-1),encoder_output),2)).tanh()\n",
    "        return torch.sum(self.v*energy,dim=2)\n",
    "    \n",
    "    def forward(self,hidden,encoder_output):\n",
    "        if self.method=='general':\n",
    "            attn_energies=self.general_score(hidden,encoder_output)\n",
    "        elif self.method='concat':\n",
    "            attn_energies=self.concat_score(hidden,encoder_output)\n",
    "        elif self.method='dot':\n",
    "            attn_energies=self.dot_score(hidden,encoder_output)\n",
    "        \n",
    "        attn_energies=attn_energies.t()\n",
    "        return F.softmax(attn_energies,dim=1).unsqueeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a2ace3bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "4\n",
      "7\n",
      "------------------------\n",
      "0.7268518518518517\n",
      "0.7804232804232804\n",
      "0.4761904761904762\n"
     ]
    }
   ],
   "source": [
    "import difflib\n",
    "import Levenshtein\n",
    "\n",
    "str1='2016-5-2'\n",
    "str2='2017-8-10'\n",
    "str3='2019-10-1'\n",
    "str4='0.60.13'\n",
    "\n",
    "\n",
    "sim12=Levenshtein.distance(str1,str2)\n",
    "sim23=Levenshtein.distance(str2,str3)\n",
    "sim34=Levenshtein.distance(str3,str4)\n",
    "\n",
    "jaro12=Levenshtein.jaro(str1,str2)\n",
    "jaro23=Levenshtein.jaro(str2,str3)\n",
    "jaro34=Levenshtein.jaro(str3,str4)\n",
    "\n",
    "print(sim12)\n",
    "print(sim23)\n",
    "print(sim34)\n",
    "print('------------------------')\n",
    "print(jaro12)\n",
    "print(jaro23)\n",
    "print(jaro34)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
